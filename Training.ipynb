{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "from os.path import basename\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from model import *\n",
    "from mining import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arousal = np.load('./DEAM/y_arousal_mean.npy')\n",
    "y_valence = np.load('./DEAM/y_valence_mean.npy')\n",
    "X = np.load('./DEAM/X_DEAM.npy')\n",
    "X = np.average(X,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "adam_optim = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working on 0 Fold\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 260)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 260)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 260)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 260)          67860       anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 780)          0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 67,860\n",
      "Trainable params: 67,860\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 40us/step - loss: 38.2799 - val_loss: 20.3510\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 19.0636 - val_loss: 12.4579\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 12.5762 - val_loss: 9.1193\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 9.1974 - val_loss: 7.2330\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 7.0944 - val_loss: 5.9929\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 5.6848 - val_loss: 5.1086\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 4.6943 - val_loss: 4.4500\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 3.9753 - val_loss: 3.9370\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 3.4394 - val_loss: 3.5357\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 3.0360 - val_loss: 3.2127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 0.1201624600617371\n",
      "r2 = 0.06750834924327187\n",
      "saving...........\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 3.1184 - val_loss: 3.0068\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 2.7363 - val_loss: 2.7247\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 2.4641 - val_loss: 2.5126\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 2.2515 - val_loss: 2.3419\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 2.0792 - val_loss: 2.2022\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 1.9368 - val_loss: 2.0854\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 1.8157 - val_loss: 1.9853\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 1.7120 - val_loss: 1.8990\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 1.6227 - val_loss: 1.8232\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 1.5439 - val_loss: 1.7584\n",
      "mse = 0.11113743602244501\n",
      "r2 = 0.13754486114719577\n",
      "saving...........\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 1.7222 - val_loss: 1.7143\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 1.5969 - val_loss: 1.6418\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 1.5070 - val_loss: 1.5847\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 1.4320 - val_loss: 1.5377\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 1.3682 - val_loss: 1.4919\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 1.3122 - val_loss: 1.4514\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 1.2620 - val_loss: 1.4160\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 1.2163 - val_loss: 1.3861\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 1.1753 - val_loss: 1.3540\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 1.1374 - val_loss: 1.3244\n",
      "mse = 0.1115909207012667\n",
      "r2 = 0.13402570319611817\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 1.3391 - val_loss: 1.3504\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 1.2511 - val_loss: 1.3096\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 1.1903 - val_loss: 1.2772\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 1.1406 - val_loss: 1.2484\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 1.0987 - val_loss: 1.2241\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 1.0619 - val_loss: 1.2042\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 1.0287 - val_loss: 1.1862\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.9986 - val_loss: 1.1693\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.9709 - val_loss: 1.1532\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.9457 - val_loss: 1.1366\n",
      "mse = 0.11538799515685107\n",
      "r2 = 0.10455942707864418\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 1.1443 - val_loss: 1.1633\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 1.0701 - val_loss: 1.1311\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 1.0215 - val_loss: 1.1055\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.9823 - val_loss: 1.0843\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.9488 - val_loss: 1.0663\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.9195 - val_loss: 1.0506\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.8928 - val_loss: 1.0343\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.8688 - val_loss: 1.0217\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.8468 - val_loss: 1.0079\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.8266 - val_loss: 0.9961\n",
      "mse = 0.11433621098425956\n",
      "r2 = 0.11272154325732231\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 1.0146 - val_loss: 1.0589\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.9524 - val_loss: 1.0351\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.9117 - val_loss: 1.0188\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.8798 - val_loss: 1.0048\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.8525 - val_loss: 0.9937\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.8285 - val_loss: 0.9793\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.8076 - val_loss: 0.9701\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.7884 - val_loss: 0.9600\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.7707 - val_loss: 0.9494\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.7545 - val_loss: 0.9428\n",
      "mse = 0.10670385986446523\n",
      "r2 = 0.17195055447426422\n",
      "saving...........\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.9184 - val_loss: 0.8578\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 0.8635 - val_loss: 0.8381\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.8278 - val_loss: 0.8228\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.7995 - val_loss: 0.8103\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.7753 - val_loss: 0.8008\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.7538 - val_loss: 0.7908\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.7350 - val_loss: 0.7838\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.7177 - val_loss: 0.7757\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.7016 - val_loss: 0.7684\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.6871 - val_loss: 0.7627\n",
      "mse = 0.09899079634814054\n",
      "r2 = 0.2318059146843815\n",
      "saving...........\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.8074 - val_loss: 0.8085\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.7584 - val_loss: 0.7918\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.7273 - val_loss: 0.7798\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.7028 - val_loss: 0.7702\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6820 - val_loss: 0.7629\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6642 - val_loss: 0.7553\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.6482 - val_loss: 0.7493\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.6338 - val_loss: 0.7429\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.6207 - val_loss: 0.7371\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112070/112070 [==============================] - 4s 36us/step - loss: 0.6083 - val_loss: 0.7326\n",
      "mse = 0.10436550462357051\n",
      "r2 = 0.19009679363678855\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.7810 - val_loss: 0.7891\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.7368 - val_loss: 0.7745\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.7081 - val_loss: 0.7631\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.6856 - val_loss: 0.7537\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6665 - val_loss: 0.7456\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.6498 - val_loss: 0.7410\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6352 - val_loss: 0.7344\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6216 - val_loss: 0.7298\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.6093 - val_loss: 0.7257\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5974 - val_loss: 0.7200\n",
      "mse = 0.10982419690643659\n",
      "r2 = 0.14773593505243898\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.7291 - val_loss: 0.7100\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.6880 - val_loss: 0.6995\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.6617 - val_loss: 0.6915\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.6404 - val_loss: 0.6863\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6228 - val_loss: 0.6817\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.6076 - val_loss: 0.6772\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.5939 - val_loss: 0.6730\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.5812 - val_loss: 0.6706\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.5699 - val_loss: 0.6666\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.5592 - val_loss: 0.6645\n",
      "mse = 0.10493411256986002\n",
      "r2 = 0.18568424946786533\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.6763 - val_loss: 0.7467\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.6368 - val_loss: 0.7322\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6113 - val_loss: 0.7206\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.5912 - val_loss: 0.7132\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.5744 - val_loss: 0.7060\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 0.5601 - val_loss: 0.7007\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.5471 - val_loss: 0.6961\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5356 - val_loss: 0.6911\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.5246 - val_loss: 0.6875\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.5149 - val_loss: 0.6828\n",
      "mse = 0.10393204029768931\n",
      "r2 = 0.19346058849066772\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6984 - val_loss: 0.6929\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6576 - val_loss: 0.6792\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.6316 - val_loss: 0.6707\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.6110 - val_loss: 0.6626\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5938 - val_loss: 0.6565\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.5787 - val_loss: 0.6520\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.5659 - val_loss: 0.6472\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 4s 35us/step - loss: 0.5540 - val_loss: 0.6441\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5431 - val_loss: 0.6387\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.5329 - val_loss: 0.6358\n",
      "mse = 0.10290365636055725\n",
      "r2 = 0.20144111281294996\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.6204 - val_loss: 0.6218\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.5840 - val_loss: 0.6116\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5609 - val_loss: 0.6044\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.5427 - val_loss: 0.5983\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.5275 - val_loss: 0.5951\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5143 - val_loss: 0.5910\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5025 - val_loss: 0.5874\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.4920 - val_loss: 0.5846\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4820 - val_loss: 0.5833\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4729 - val_loss: 0.5802\n",
      "mse = 0.10347987072858984\n",
      "r2 = 0.1969695408514539\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.6100 - val_loss: 0.6255\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.5739 - val_loss: 0.6140\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.5515 - val_loss: 0.6063\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5341 - val_loss: 0.6003\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.5192 - val_loss: 0.5962\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.5066 - val_loss: 0.5916\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4953 - val_loss: 0.5885\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4851 - val_loss: 0.5863\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4757 - val_loss: 0.5826\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4672 - val_loss: 0.5811\n",
      "mse = 0.09959452559566496\n",
      "r2 = 0.22712082016863244\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5665 - val_loss: 0.5711\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.5310 - val_loss: 0.5609\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5087 - val_loss: 0.5541\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.4917 - val_loss: 0.5493\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4775 - val_loss: 0.5461\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4654 - val_loss: 0.5425\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4548 - val_loss: 0.5396\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4451 - val_loss: 0.5371\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4365 - val_loss: 0.5346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4286 - val_loss: 0.5326\n",
      "mse = 0.10031603014873108\n",
      "r2 = 0.2215217589362687\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5611 - val_loss: 0.5369\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.5270 - val_loss: 0.5276\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.5059 - val_loss: 0.5206\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 0.4897 - val_loss: 0.5163\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4762 - val_loss: 0.5128\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4644 - val_loss: 0.5095\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.4545 - val_loss: 0.5066\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4450 - val_loss: 0.5041\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4365 - val_loss: 0.5018\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4286 - val_loss: 0.4997\n",
      "mse = 0.09994509227026478\n",
      "r2 = 0.2244003324478424\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.5586 - val_loss: 0.5583\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.5222 - val_loss: 0.5486\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4999 - val_loss: 0.5436\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.4826 - val_loss: 0.5404\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.4683 - val_loss: 0.5351\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 0.4562 - val_loss: 0.5310\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4451 - val_loss: 0.5286\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4354 - val_loss: 0.5261\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4266 - val_loss: 0.5260\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4185 - val_loss: 0.5221\n",
      "mse = 0.09466529137870798\n",
      "r2 = 0.26537294774304454\n",
      "saving...........\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.5496 - val_loss: 0.5563\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.5149 - val_loss: 0.5474\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4930 - val_loss: 0.5411\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4762 - val_loss: 0.5364\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.4624 - val_loss: 0.5313\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4505 - val_loss: 0.5293\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4400 - val_loss: 0.5267\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4305 - val_loss: 0.5250\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4219 - val_loss: 0.5222\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.4140 - val_loss: 0.5206\n",
      "mse = 0.09973060738441475\n",
      "r2 = 0.22606479042553274\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.5210 - val_loss: 0.5150\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.4887 - val_loss: 0.5057\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.4689 - val_loss: 0.4997\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4535 - val_loss: 0.4970\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4408 - val_loss: 0.4930\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.4297 - val_loss: 0.4901\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.4199 - val_loss: 0.4884\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4112 - val_loss: 0.4867\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4032 - val_loss: 0.4852\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.3959 - val_loss: 0.4821\n",
      "mse = 0.09473545921518191\n",
      "r2 = 0.264828427252785\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.4982 - val_loss: 0.4974\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4663 - val_loss: 0.4873\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4466 - val_loss: 0.4809\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4314 - val_loss: 0.4759\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4187 - val_loss: 0.4710\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4080 - val_loss: 0.4689\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.3985 - val_loss: 0.4653\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.3901 - val_loss: 0.4627\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.3822 - val_loss: 0.4611\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.3750 - val_loss: 0.4587\n",
      "mse = 0.10057196953256753\n",
      "r2 = 0.21953560337316946\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4774 - val_loss: 0.4784\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 0.4471 - val_loss: 0.4703\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.4286 - val_loss: 0.4643\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.4142 - val_loss: 0.4596\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.4026 - val_loss: 0.4560\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3924 - val_loss: 0.4532\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.3834 - val_loss: 0.4505\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3753 - val_loss: 0.4483\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3678 - val_loss: 0.4460\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.3610 - val_loss: 0.4444\n",
      "mse = 0.10314042107067302\n",
      "r2 = 0.19960375765840865\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.4678 - val_loss: 0.4547\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.4369 - val_loss: 0.4444\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.4176 - val_loss: 0.4385\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4031 - val_loss: 0.4342\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.3912 - val_loss: 0.4307\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.3809 - val_loss: 0.4283\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 4s 34us/step - loss: 0.3717 - val_loss: 0.4269\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.3637 - val_loss: 0.4246\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.3563 - val_loss: 0.4230\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3497 - val_loss: 0.4206\n",
      "mse = 0.0959287336428779\n",
      "r2 = 0.25556831023856663\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.4300 - val_loss: 0.4353\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4008 - val_loss: 0.4259\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.3827 - val_loss: 0.4213\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.3688 - val_loss: 0.4164\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.3574 - val_loss: 0.4141\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3476 - val_loss: 0.4134\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.3390 - val_loss: 0.4092\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.3314 - val_loss: 0.4085\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.3244 - val_loss: 0.4074\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.3180 - val_loss: 0.4063\n",
      "mse = 0.09791521739554773\n",
      "r2 = 0.24015268448675697\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 0.4416 - val_loss: 0.4445\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 0.4118 - val_loss: 0.4376\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3940 - val_loss: 0.4326\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 0.3805 - val_loss: 0.4289\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 3s 28us/step - loss: 0.3693 - val_loss: 0.4262\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3595 - val_loss: 0.4233\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 29us/step - loss: 0.3512 - val_loss: 0.4216\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3436 - val_loss: 0.4200\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.3369 - val_loss: 0.4188\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.3304 - val_loss: 0.4166\n",
      "mse = 0.09739139490905481\n",
      "r2 = 0.24421768194837956\n",
      "Train on 112070 samples, validate on 48080 samples\n",
      "Epoch 1/10\n",
      "112070/112070 [==============================] - 3s 31us/step - loss: 0.4237 - val_loss: 0.4436\n",
      "Epoch 2/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.3960 - val_loss: 0.4377\n",
      "Epoch 3/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.3794 - val_loss: 0.4329\n",
      "Epoch 4/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.3666 - val_loss: 0.4292\n",
      "Epoch 5/10\n",
      "112070/112070 [==============================] - 4s 33us/step - loss: 0.3557 - val_loss: 0.4269\n",
      "Epoch 6/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3467 - val_loss: 0.4248\n",
      "Epoch 7/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3385 - val_loss: 0.4227\n",
      "Epoch 8/10\n",
      "112070/112070 [==============================] - 3s 30us/step - loss: 0.3313 - val_loss: 0.4216\n",
      "Epoch 9/10\n",
      "112070/112070 [==============================] - 4s 31us/step - loss: 0.3245 - val_loss: 0.4203\n",
      "Epoch 10/10\n",
      "112070/112070 [==============================] - 4s 32us/step - loss: 0.3182 - val_loss: 0.4181\n",
      "mse = 0.09899568341495353\n",
      "r2 = 0.23176798978672664\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "set_session(tf.Session(config=config))        \n",
    "    \n",
    "input_dim = X.shape[1]\n",
    "anchor_input = Input((input_dim, ), name='anchor_input')\n",
    "positive_input = Input((input_dim, ), name='positive_input')\n",
    "negative_input = Input((input_dim, ), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = create_base_network(input_dim, 260)\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1)\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "arousal_scaler = MinMaxScaler((-1,1))\n",
    "valence_scaler = MinMaxScaler((-1,1))\n",
    "\n",
    "svm_r2_history = []\n",
    "svm_mse_history = []\n",
    "\n",
    "total_fold = 10\n",
    "kf = KFold(n_splits=total_fold, random_state=101)\n",
    "fold = 0\n",
    "for i in kf.split(X,y_arousal):\n",
    "    print('Now working on {} Fold'.format(fold))\n",
    "    train_index = i[0]\n",
    "    test_index = i[1]\n",
    "    \n",
    "    X_train_norm = X_scaler.fit_transform(X[train_index])\n",
    "    X_test_norm = X_scaler.transform(X[test_index])\n",
    "    \n",
    "    y_a_train_norm = arousal_scaler.fit_transform(y_arousal[train_index].reshape(-1,1))\n",
    "    y_a_test_norm = arousal_scaler.transform(y_arousal[test_index].reshape(-1,1))\n",
    "    \n",
    "    y_v_train_norm = valence_scaler.fit_transform(y_valence[train_index].reshape(-1,1))\n",
    "    y_v_test_norm = valence_scaler.transform(y_valence[test_index].reshape(-1,1))\n",
    "    \n",
    "    y_train_R_norm = y_v_train_norm # This model is training on valence, to train on arousal, just change this line\n",
    "    y_test_R_norm = y_v_test_norm\n",
    "\n",
    "    model.compile(loss=triplet_loss, optimizer=adam_optim)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    total_loss_history = []\n",
    "    total_valloss_history = []\n",
    "    r2_history = []\n",
    "    baseline_r2_history = []\n",
    "    mse_history = []\n",
    "    baseline_mse_history =[]\n",
    "    for i in range(25): # Mining triplets for 25 times\n",
    "        if i == 0:\n",
    "            r2_old=0\n",
    "            r2 = 0\n",
    "        else:\n",
    "            # if r2 > r2_old:\n",
    "            # model.save_weights(foldername + filename + '.hdf5')\n",
    "            # else:\n",
    "            pass\n",
    "                \n",
    "        \n",
    "        \n",
    "        if r2 > r2_old:\n",
    "            print('saving...........')\n",
    "            r2_old = r2 #saving old r2 for comparison\n",
    "            set_folder = './TNN_training/'\n",
    "            filename = 'GBM_valence_{}_of_{}fold_triplet_260_'.format(fold, total_fold) + str(i) + 'nd_r2-' + str(r2)\n",
    "            try:\n",
    "                foldername = set_folder\n",
    "                filename=filename\n",
    "                model.save_weights(foldername+filename+'.hdf5')\n",
    "            except:\n",
    "                os.mkdir(set_folder)\n",
    "                filename=filename\n",
    "                model.save_weights(foldername+filename+'.hdf5')                \n",
    "        \n",
    "        triplet_train, triplet_test = generate_triplet_R(X_train_norm,y_train_R_norm,positive_range=0.1, negative_range=0.5,  ap_pairs=10,an_pairs=10)\n",
    "        Anchor = triplet_train[:,0,:]\n",
    "        Positive = triplet_train[:,1,:]\n",
    "        Negative = triplet_train[:,2,:]\n",
    "        Anchor_test = triplet_test[:,0,:]\n",
    "        Positive_test = triplet_test[:,1,:]\n",
    "        Negative_test = triplet_test[:,2,:]\n",
    "        Y_dummy = np.empty((Anchor.shape[0],1))\n",
    "        Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "\n",
    "\n",
    "        history = model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), batch_size=128, epochs=10,verbose=True)\n",
    "        total_loss_history = total_loss_history + history.history['loss']\n",
    "        total_valloss_history = total_valloss_history + history.history['val_loss']\n",
    "\n",
    "        trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)\n",
    "        transformed_X_train = trained_model.predict(X_train_norm)\n",
    "        transformed_X_test = trained_model.predict(X_test_norm)\n",
    "\n",
    "        regressor_model = GradientBoostingRegressor()\n",
    "        regressor_model.fit(transformed_X_train, y_train_R_norm)\n",
    "\n",
    "        gradboost_y_pred_norm = regressor_model.predict(transformed_X_test)\n",
    "        # gradboost_y_pred = scaler_yv.inverse_transform(gradboost_y_pred_norm.reshape(-1,1))\n",
    "\n",
    "        mse = mean_squared_error(y_test_R_norm,gradboost_y_pred_norm)\n",
    "        r2 = r2_score(y_test_R_norm, gradboost_y_pred_norm)\n",
    "        print('mse = {}'.format(mse))\n",
    "        print('r2 = {}'.format(r2))   \n",
    "        r2_history.append(r2)\n",
    "        mse_history.append(mse)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=[15,5])\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.set_xlabel('epochs')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax1.plot(total_loss_history)\n",
    "    ax1.plot(total_valloss_history)\n",
    "    ax1.legend(['loss','val_loss'])\n",
    "\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.set_xlabel('epochs')\n",
    "    ax2.set_ylabel('r2')\n",
    "    ax2.plot(r2_history)\n",
    "    ax2.plot(baseline_r2_history)\n",
    "    ax2.legend(['r2'])\n",
    "    pickle.dump(r2_history, open('GBM_valence_{}_of_{}fold_r2'.format(fold,total_fold), 'wb'))\n",
    "    pickle.dump(mse_history,open('GBM_valence_{}_of_{}fold_mse'.format(fold,total_fold), 'wb'))\n",
    "    fig.savefig('GBM_valence_training_loss_{}_of_{}fold'.format(fold,total_fold))\n",
    "    fold+=1       \n",
    "    \n",
    "    break # for demonstration, we just try on 1 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
